<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="SELECTIVE" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="daa0b559-4a67-4c38-be44-a40896582039" name="Default Changelist" comment="Now the function crop_frame_to_pose allows to choose the &quot;limits&quot; that will be added to bbox (to make cropped frame wider) to avoid overcropping.">
      <change beforePath="$PROJECT_DIR$/.idea/datatools.iml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/datatools.iml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
    </list>
    <list id="31e5016d-9ac8-45e6-bc63-f2f72cd9eea4" name="tmp" comment="" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="FlaskConsoleOptions" custom-start-script="import sys&#10;sys.path.extend([WORKING_DIR_AND_PYTHON_PATHS])&#10;from flask.cli import ScriptInfo&#10;locals().update(ScriptInfo(create_app=None).load_app().make_shell_context())&#10;print(&quot;Python %s on %s\nApp: %s [%s]\nInstance: %s&quot; % (sys.version, sys.platform, app.import_name, app.env, app.instance_path))">
    <envs>
      <env key="FLASK_APP" value="app" />
    </envs>
    <option name="myCustomStartScript" value="import sys&#10;sys.path.extend([WORKING_DIR_AND_PYTHON_PATHS])&#10;from flask.cli import ScriptInfo&#10;locals().update(ScriptInfo(create_app=None).load_app().make_shell_context())&#10;print(&quot;Python %s on %s\nApp: %s [%s]\nInstance: %s&quot; % (sys.version, sys.platform, app.import_name, app.env, app.instance_path))" />
    <option name="myEnvs">
      <map>
        <entry key="FLASK_APP" value="app" />
      </map>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
    <option name="RESET_MODE" value="HARD" />
    <option name="ROOT_SYNC" value="DONT_SYNC" />
  </component>
  <component name="MarkdownSettingsMigration">
    <option name="stateVersion" value="1" />
  </component>
  <component name="ProjectId" id="1qko2UVoIziYhK9BCHr91cqDNpH" />
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">{
  &quot;keyToString&quot;: {
    &quot;WebServerToolWindowFactoryState&quot;: &quot;true&quot;,
    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;
  }
}</component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="C:\Users\Denis\PycharmProjects\datatools\preprocessing\data_preprocessing" />
      <recent name="C:\Users\Denis\PycharmProjects\datatools\keras_datagenerators" />
    </key>
  </component>
  <component name="RunManager" selected="Python.embeddings_extraction_audio_torch">
    <configuration name="embeddings_extraction_audio_torch" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="datatools" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/feature_extraction" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/feature_extraction/embeddings_extraction_audio_torch.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="face_recognition_utils" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="datatools" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/preprocessing" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/preprocessing/face_recognition_utils.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="torch_visualizations" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="datatools" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/visualization" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/visualization/torch_visualizations.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="video_preprocessing_utils" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="datatools" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/preprocessing/data_preprocessing" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/preprocessing/data_preprocessing/video_preprocessing_utils.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <recent_temporary>
      <list>
        <item itemvalue="Python.embeddings_extraction_audio_torch" />
        <item itemvalue="Python.torch_visualizations" />
        <item itemvalue="Python.video_preprocessing_utils" />
        <item itemvalue="Python.face_recognition_utils" />
      </list>
    </recent_temporary>
  </component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="daa0b559-4a67-4c38-be44-a40896582039" name="Default Changelist" comment="" />
      <created>1617632741330</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1617632741330</updated>
      <workItem from="1694174053740" duration="2180000" />
      <workItem from="1699369206251" duration="23000" />
      <workItem from="1700730949187" duration="49000" />
      <workItem from="1701165537298" duration="16000" />
      <workItem from="1706541717534" duration="2185000" />
      <workItem from="1706545630968" duration="3955000" />
      <workItem from="1706696350031" duration="1754000" />
      <workItem from="1706719271115" duration="237000" />
      <workItem from="1706778119743" duration="2182000" />
      <workItem from="1706891586467" duration="144000" />
      <workItem from="1707128307785" duration="105000" />
      <workItem from="1707158442794" duration="62000" />
    </task>
    <task id="LOCAL-00001" summary="First commit">
      <created>1617633794015</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1617633794015</updated>
    </task>
    <task id="LOCAL-00002" summary="The names of files with audio generators were changed.">
      <created>1618254963184</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1618254963184</updated>
    </task>
    <task id="LOCAL-00003" summary="The file represented Image loading and preproecssing (as generator) was added.">
      <created>1618254993767</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1618254993767</updated>
    </task>
    <task id="LOCAL-00004" summary="The extracting frames from all videos function was changes so as now it walk through all the directories and subdirectories of defined directory.">
      <created>1618340438427</created>
      <option name="number" value="00004" />
      <option name="presentableId" value="LOCAL-00004" />
      <option name="project" value="LOCAL" />
      <updated>1618340438427</updated>
    </task>
    <task id="LOCAL-00005" summary="New package was created - data_preprocessing. Now, all the preprocessing functions devoted to data (audio, visual, etc.) is located in data_preprocessing package.">
      <created>1618341699647</created>
      <option name="number" value="00005" />
      <option name="presentableId" value="LOCAL-00005" />
      <option name="project" value="LOCAL" />
      <updated>1618341699647</updated>
    </task>
    <task id="LOCAL-00006" summary="The possibility to skip every n frames during frames extraction from videofile is added.">
      <created>1618393715164</created>
      <option name="number" value="00006" />
      <option name="presentableId" value="LOCAL-00006" />
      <option name="project" value="LOCAL" />
      <updated>1618393715164</updated>
    </task>
    <task id="LOCAL-00007" summary="New functions for face recognition, extraction (from image) and retinaFace model loading were added.">
      <created>1618393768607</created>
      <option name="number" value="00007" />
      <option name="presentableId" value="LOCAL-00007" />
      <option name="project" value="LOCAL" />
      <updated>1618393768607</updated>
    </task>
    <task id="LOCAL-00008" summary="New function for resizing image was added.">
      <created>1618407450277</created>
      <option name="number" value="00008" />
      <option name="presentableId" value="LOCAL-00008" />
      <option name="project" value="LOCAL" />
      <updated>1618407450277</updated>
    </task>
    <task id="LOCAL-00009" summary="New function for loading all images from directory was added.">
      <created>1620831997062</created>
      <option name="number" value="00009" />
      <option name="presentableId" value="LOCAL-00009" />
      <option name="project" value="LOCAL" />
      <updated>1620831997062</updated>
    </task>
    <task id="LOCAL-00010" summary="Functions for extracting deep embeddings given extractor model was added. Now it is possible to extract embeddings from all images in directory or from batch of images.">
      <created>1620832046845</created>
      <option name="number" value="00010" />
      <option name="presentableId" value="LOCAL-00010" />
      <option name="project" value="LOCAL" />
      <updated>1620832046845</updated>
    </task>
    <task id="LOCAL-00011" summary="New function for direct recognition of one most probable face has been added.">
      <created>1694010961805</created>
      <option name="number" value="00011" />
      <option name="presentableId" value="LOCAL-00011" />
      <option name="project" value="LOCAL" />
      <updated>1694010961805</updated>
    </task>
    <task id="LOCAL-00012" summary="The possibility to pass the numpy array as an input to resize_image_saving_aspect_ratio function has been added.">
      <created>1694011036198</created>
      <option name="number" value="00012" />
      <option name="presentableId" value="LOCAL-00012" />
      <option name="project" value="LOCAL" />
      <updated>1694011036198</updated>
    </task>
    <task id="LOCAL-00013" summary="A new file for wrappers of different GradCam techniques has been created. It contains now only testing of the pytorch_grad_cam library.">
      <created>1694011080090</created>
      <option name="number" value="00013" />
      <option name="presentableId" value="LOCAL-00013" />
      <option name="project" value="LOCAL" />
      <updated>1694011080090</updated>
    </task>
    <task id="LOCAL-00014" summary="Two new functions have been added. They are wrappers for different GradCAM visualizators. Works stable.">
      <created>1694177469620</created>
      <option name="number" value="00014" />
      <option name="presentableId" value="LOCAL-00014" />
      <option name="project" value="LOCAL" />
      <updated>1694177469620</updated>
    </task>
    <task id="LOCAL-00015" summary="The option to save confusion marix as a file has been added. Default if None.">
      <created>1700730980350</created>
      <option name="number" value="00015" />
      <option name="presentableId" value="LOCAL-00015" />
      <option name="project" value="LOCAL" />
      <updated>1700730980350</updated>
    </task>
    <task id="LOCAL-00016" summary="A new class for the extraction of audio embeddings has been added. It maintains several feature extraction models such as Wav2Vec2, HuBERT, AST.">
      <created>1706542888928</created>
      <option name="number" value="00016" />
      <option name="presentableId" value="LOCAL-00016" />
      <option name="project" value="LOCAL" />
      <updated>1706542888928</updated>
    </task>
    <task id="LOCAL-00017" summary="The feature extraction scripts have been reallocated according to their belonging to either torch or tensorflow.">
      <created>1706719353794</created>
      <option name="number" value="00017" />
      <option name="presentableId" value="LOCAL-00017" />
      <option name="project" value="LOCAL" />
      <updated>1706719353794</updated>
    </task>
    <task id="LOCAL-00018" summary="The feature extraction scripts have been reallocated according to their belonging to either torch or tensorflow.">
      <created>1706719381964</created>
      <option name="number" value="00018" />
      <option name="presentableId" value="LOCAL-00018" />
      <option name="project" value="LOCAL" />
      <updated>1706719381964</updated>
    </task>
    <task id="LOCAL-00019" summary="The feature extraction scripts have been reallocated according to their belonging to either torch or tensorflow.">
      <created>1706719423361</created>
      <option name="number" value="00019" />
      <option name="presentableId" value="LOCAL-00019" />
      <option name="project" value="LOCAL" />
      <updated>1706719423361</updated>
    </task>
    <task id="LOCAL-00020" summary="The feature extraction scripts have been reallocated according to their belonging to either torch or tensorflow.">
      <created>1706719449147</created>
      <option name="number" value="00020" />
      <option name="presentableId" value="LOCAL-00020" />
      <option name="project" value="LOCAL" />
      <updated>1706719449147</updated>
    </task>
    <task id="LOCAL-00021" summary="A new script for operating with DeepFace library has been written. Uses entirely the DeepFace models. Tested.">
      <created>1706891625166</created>
      <option name="number" value="00021" />
      <option name="presentableId" value="LOCAL-00021" />
      <option name="project" value="LOCAL" />
      <updated>1706891625166</updated>
    </task>
    <task id="LOCAL-00022" summary="Critical fix for the __extract_embeddings_one_image function(). Now, the input image will be preprocessed as it was intended.">
      <created>1706891664907</created>
      <option name="number" value="00022" />
      <option name="presentableId" value="LOCAL-00022" />
      <option name="project" value="LOCAL" />
      <updated>1706891664907</updated>
    </task>
    <task id="LOCAL-00023" summary="Embeddings sizes for available models as well as the function to get those sizes have been added.">
      <created>1706891687163</created>
      <option name="number" value="00023" />
      <option name="presentableId" value="LOCAL-00023" />
      <option name="project" value="LOCAL" />
      <updated>1706891687163</updated>
    </task>
    <task id="LOCAL-00024" summary="Small example to check if the work of the script has been added">
      <created>1706891723358</created>
      <option name="number" value="00024" />
      <option name="presentableId" value="LOCAL-00024" />
      <option name="project" value="LOCAL" />
      <updated>1706891723358</updated>
    </task>
    <task id="LOCAL-00025" summary="Now the function crop_frame_to_pose allows to choose the &quot;limits&quot; that will be added to bbox (to make cropped frame wider) to avoid overcropping.">
      <created>1707158490996</created>
      <option name="number" value="00025" />
      <option name="presentableId" value="LOCAL-00025" />
      <option name="project" value="LOCAL" />
      <updated>1707158490996</updated>
    </task>
    <option name="localTasksCounter" value="26" />
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State />
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="VcsManagerConfiguration">
    <MESSAGE value="First commit" />
    <MESSAGE value="The names of files with audio generators were changed." />
    <MESSAGE value="The file represented Image loading and preproecssing (as generator) was added." />
    <MESSAGE value="The extracting frames from all videos function was changes so as now it walk through all the directories and subdirectories of defined directory." />
    <MESSAGE value="New package was created - data_preprocessing. Now, all the preprocessing functions devoted to data (audio, visual, etc.) is located in data_preprocessing package." />
    <MESSAGE value="The possibility to skip every n frames during frames extraction from videofile is added." />
    <MESSAGE value="New functions for face recognition, extraction (from image) and retinaFace model loading were added." />
    <MESSAGE value="New function for resizing image was added." />
    <MESSAGE value="New function for loading all images from directory was added." />
    <MESSAGE value="Functions for extracting deep embeddings given extractor model was added. Now it is possible to extract embeddings from all images in directory or from batch of images." />
    <MESSAGE value="New function for direct recognition of one most probable face has been added." />
    <MESSAGE value="The possibility to pass the numpy array as an input to resize_image_saving_aspect_ratio function has been added." />
    <MESSAGE value="A new file for wrappers of different GradCam techniques has been created. It contains now only testing of the pytorch_grad_cam library." />
    <MESSAGE value="Two new functions have been added. They are wrappers for different GradCAM visualizators. Works stable." />
    <MESSAGE value="The option to save confusion marix as a file has been added. Default if None." />
    <MESSAGE value="A new class for the extraction of audio embeddings has been added. It maintains several feature extraction models such as Wav2Vec2, HuBERT, AST." />
    <MESSAGE value="The feature extraction scripts have been reallocated according to their belonging to either torch or tensorflow." />
    <MESSAGE value="A new script for operating with DeepFace library has been written. Uses entirely the DeepFace models. Tested." />
    <MESSAGE value="Critical fix for the __extract_embeddings_one_image function(). Now, the input image will be preprocessed as it was intended." />
    <MESSAGE value="Embeddings sizes for available models as well as the function to get those sizes have been added." />
    <MESSAGE value="Small example to check if the work of the script has been added" />
    <MESSAGE value="Now the function crop_frame_to_pose allows to choose the &quot;limits&quot; that will be added to bbox (to make cropped frame wider) to avoid overcropping." />
    <option name="LAST_COMMIT_MESSAGE" value="Now the function crop_frame_to_pose allows to choose the &quot;limits&quot; that will be added to bbox (to make cropped frame wider) to avoid overcropping." />
  </component>
  <component name="XDebuggerManager">
    <breakpoint-manager>
      <breakpoints>
        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
          <url>file://$PROJECT_DIR$/preprocessing/data_preprocessing/video_preprocessing_utils.py</url>
          <line>75</line>
          <option name="timeStamp" value="12" />
        </line-breakpoint>
      </breakpoints>
    </breakpoint-manager>
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/datatools$fdfd.coverage" NAME="fdfd Coverage Results" MODIFIED="1675422588152" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/models/Pose_estimation" />
    <SUITE FILE_PATH="coverage/datatools$Dense_models.coverage" NAME="Dense_models Coverage Results" MODIFIED="1656662133203" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/models" />
    <SUITE FILE_PATH="coverage/datatools$torch_visualizations.coverage" NAME="torch_visualizations Coverage Results" MODIFIED="1694177413618" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/visualization" />
    <SUITE FILE_PATH="coverage/datatools$losses.coverage" NAME="losses Coverage Results" MODIFIED="1660298038817" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils" />
    <SUITE FILE_PATH="coverage/datatools$CNN_models.coverage" NAME="CNN_models Coverage Results" MODIFIED="1675429266891" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/models" />
    <SUITE FILE_PATH="coverage/datatools$ImageDataGenerator.coverage" NAME="ImageDataGenerator Coverage Results" MODIFIED="1656507178373" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/generators" />
    <SUITE FILE_PATH="coverage/datatools$TimeDistributed_layer.coverage" NAME="TimeDistributed_layer Coverage Results" MODIFIED="1675350962550" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/layers" />
    <SUITE FILE_PATH="coverage/datatools$ImageDataLoader_tf2.coverage" NAME="ImageDataLoader_tf2 Coverage Results" MODIFIED="1646838635507" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/tensorflow_utils/tensorflow_datagenerators" />
    <SUITE FILE_PATH="coverage/datatools$gradcam.coverage" NAME="gradcam Coverage Results" MODIFIED="1693994697400" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/visualization/utkuozbulak_lib" />
    <SUITE FILE_PATH="coverage/datatools$RNN_models.coverage" NAME="RNN_models Coverage Results" MODIFIED="1656661911520" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/pytorch_utils/models" />
    <SUITE FILE_PATH="coverage/datatools$embeddings_extraction_audio_torch.coverage" NAME="embeddings_extraction_audio_torch Coverage Results" MODIFIED="1706696423631" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/feature_extraction" />
  </component>
</project>